{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXSL314rVexH",
        "colab_type": "text"
      },
      "source": [
        "# Text preprocessing with Spacy \n",
        "\n",
        "(Alternatives can be torchtext, keras text-preprocessing module, gensim, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l4M48p0VSDV",
        "colab_type": "text"
      },
      "source": [
        "## Installing required libraries and files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4G7btFt0jL6",
        "colab_type": "code",
        "outputId": "1206724e-defd-45e7-f1cb-002fbd68efb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz#egg=en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 826.9MB 1.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/__main__.py\", line 35, in <module>\n",
            "    plac.call(commands[command], sys.argv[1:])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/plac_core.py\", line 328, in call\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfU5aIxo0r6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "nlp=spacy.load(\"en_core_web_md\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoWSYDIP0pp0",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "revNmYAI06ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# open file and read the data\n",
        "\n",
        "with open(\"sample-train\",\"r\") as file:\n",
        "  string = file.read()\n",
        "  sentences = string.lower().strip().split(\"\\n\")                     # this converts the data into a list of sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WmMFyPK2BSI",
        "colab_type": "code",
        "outputId": "b22d0200-a7a0-4004-d149-4c36e4497000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# total no. of sentences in the provided sample dataset\n",
        "\n",
        "len(sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm-v_oDj2HOM",
        "colab_type": "code",
        "outputId": "d0774b35-8cec-4d8d-9915-a6c34fecab39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# example sentences\n",
        "\n",
        "sentences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'love finding out important things about my friends over twitter and snapchat... ðŸ˜’'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AhavZNBW_RW",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHwpp2Wp9Yuo",
        "colab_type": "code",
        "outputId": "53a0845e-292a-4642-9a58-be82ffd4a0cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######### test ###########\n",
        "\n",
        "tokens = sentences[0].split()                           #see how the split function breaks the sentence into tokens\n",
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['love', 'finding', 'out', 'important', 'things', 'about', 'my', 'friends', 'over', 'twitter', 'and', 'snapchat...', 'ðŸ˜’']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZfGTOjZ8rnK",
        "colab_type": "code",
        "outputId": "eee5b574-2269-4f7e-a96e-14a63070f8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######### test ###########\n",
        "\n",
        "tokens = nlp(sentences[0])                               # see how spacy breaks the sentence and analyse the difference\n",
        "print([tok.text for tok in tokens])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['love', 'finding', 'out', 'important', 'things', 'about', 'my', 'friends', 'over', 'twitter', 'and', 'snapchat', '...', 'ðŸ˜’']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v59SEVs_0U-",
        "colab_type": "code",
        "outputId": "6f60e209-a2b9-4bfd-f254-ecff7d968f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######### test ###########\n",
        "\n",
        "tokens = \"what is wrong.Don't disturb me\".split()\n",
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'is', \"wrong.Don't\", 'disturb', 'me']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u99kuBns_sgE",
        "colab_type": "code",
        "outputId": "1c127780-0b1a-4069-feaf-c742141a4bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######### test ###########\n",
        "\n",
        "tokens = nlp(\"what is wrong.Don't disturb me ncjfkdls.\")\n",
        "print([tok.text for tok in tokens])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'is', 'wrong', '.', \"Don't\", 'disturb', 'me', 'ncjfkdls', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITUwrbDQGDMb",
        "colab_type": "code",
        "outputId": "6f9869e6-41cf-4d13-c770-1a883341d5ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# other attributes provided by spacy\n",
        "\n",
        "for token in tokens:\n",
        "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what True 5.135811 False\n",
            "is True 4.890306 False\n",
            "wrong True 5.3789964 False\n",
            ". True 4.9316354 False\n",
            "Don't True 7.6098676 False\n",
            "disturb True 6.343346 False\n",
            "me True 5.75488 False\n",
            "ncjfkdls False 0.0 True\n",
            ". True 4.9316354 False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoygUQweXPcg",
        "colab_type": "text"
      },
      "source": [
        "## Reading data labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCgVaJp2PvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading labels\n",
        "\n",
        "labels = pd.read_csv(\"sample-train-label\", header=None, names = [\"labels\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMXkYRkp34cN",
        "colab_type": "code",
        "outputId": "01117426-9e63-4084-efca-fc346aa475bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   labels\n",
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2UV0Nb6XXlK",
        "colab_type": "text"
      },
      "source": [
        "## Creating a vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "243ed0a6-09ad-4599-e073-8c91614e0805",
        "id": "OQ9PRDaVGNES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# this code block basically accounts for each word in the text\n",
        "\n",
        "words = []\n",
        "sen_list=[]\n",
        "\n",
        "for sen in sentences:\n",
        "  tokens = nlp(sen)\n",
        "  temp = [tok.text for tok in tokens]\n",
        "  sen_list.append(temp)\n",
        "  words+=temp\n",
        "  \n",
        "\n",
        "print(len(sen_list))\n",
        "print(sen_list[0])\n",
        "print(\"Total no. of words in the text: \",len(words))\n",
        "words = list(set(words))\n",
        "print(\"No. of unique words: \",len(words))\n",
        "print(words[:30])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "['love', 'finding', 'out', 'important', 'things', 'about', 'my', 'friends', 'over', 'twitter', 'and', 'snapchat', '...', 'ðŸ˜’']\n",
            "Total no. of words in the text:  3854\n",
            "No. of unique words:  1491\n",
            "['@arvindkejriwal', 'http://t.co/fvmol1kltx', 'paid', '@', 'attractive', '@billbarnwell', 'soexcited', 'p', 'sound', 'twitter', 'deserve', 'but', 'tshirt', 'thinking', 'seems', '*', 'highway', 'too', 'hospital', 'writing', 'their', 'thrash', 'i', 'dramatictvactress', 'o_o', 'service', 'watch', '5x11', 'row', 'ariana']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJmvM7oVFuMi",
        "colab_type": "code",
        "outputId": "661e3f46-bfaf-4dd1-f560-dcac8d5c95c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "vocab = []\n",
        "\n",
        "print(len(nlp.vocab.strings))                          # shows all the words already present in the spacy vocabulary\n",
        "print(\"@billbarnwell\" in nlp.vocab.strings)\n",
        "print(\"what\" in nlp.vocab.strings)\n",
        "print(len(nlp.vocab.strings))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1476551\n",
            "True\n",
            "True\n",
            "1476551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WQm0ZRpX1Tf",
        "colab_type": "text"
      },
      "source": [
        "### Note:\n",
        "\n",
        "If you pass any sentence with new words into the spacy nlp module, it adds these new words into its default vocabulary. Thus these words will no longer be new for the vocabulary the next time they are encountered.\n",
        "Thus, it is advisable to reload the module in order to reset the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ah8uKF-NE-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYt4OpRTIveg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating vocabulary out of the given words\n",
        "\n",
        "vocab = [\"<pad>\",\"<unk>\",\"<start>\",\"<end>\"]\n",
        "\n",
        "for word in words:\n",
        "  if word in nlp.vocab.strings:                         # only take common words, which are already present in the nlp vocabulary\n",
        "    vocab.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VGZTfavJ00H",
        "colab_type": "code",
        "outputId": "eb0f5c2f-5c2a-442c-a6c8-66f47fef642e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# checking the custom vocabulary attributes\n",
        "\n",
        "print(len(vocab))\n",
        "print(vocab[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1284\n",
            "['<pad>', '<unk>', '<start>', '<end>', 'paid', '@', 'attractive', 'p', 'sound', 'twitter', 'deserve', 'but', 'tshirt', 'thinking', 'seems', '*', 'highway', 'too', 'hospital', 'writing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVBy9htVY7gv",
        "colab_type": "text"
      },
      "source": [
        "## Creting Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhGBo2NrJ6_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2word = {i:vocab[i] for i in range(len(vocab))}                   # mapping form index to word\n",
        "word2idx = {word:idx for idx,word in idx2word.items()}               # mapping from words to indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HuIUOhFKmrs",
        "colab_type": "code",
        "outputId": "7d76a80e-8f9f-4652-b3a8-8bd8a77ab71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(word2idx[\"what\"])\n",
        "print(word2idx[\"<pad>\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6VGWQHvKyNc",
        "colab_type": "code",
        "outputId": "6a2a8d5a-96c7-4b64-d576-880ca6a8f9c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(idx2word[1])\n",
        "print(idx2word[22])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<unk>\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOpu_4sOZI8Q",
        "colab_type": "text"
      },
      "source": [
        "## Converting sentences to sequence of indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JvHjB4cK4q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_indices(sentences):\n",
        "  indices=[]\n",
        "  count=0\n",
        "  \n",
        "  for sentence in sentences:\n",
        "    \n",
        "    index=[word2idx[\"<start>\"]]\n",
        "    \n",
        "    for i in list(nlp(sentence.lower())):\n",
        "      if i.text in vocab:\n",
        "        #print(i.text,type(i.text))\n",
        "        index.append(word2idx[i.text])\n",
        "        \n",
        "      else:\n",
        "        #print(\"unknown encountered\")\n",
        "        index.append(word2idx[\"<unk>\"])\n",
        "        \n",
        "    index.append(word2idx[\"<end>\"])\n",
        "    indices.append(index)\n",
        "    #count=count+1\n",
        "    #print(count)\n",
        "  return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16LH6iQ7MxdA",
        "colab_type": "code",
        "outputId": "ca3205ec-fcf1-497f-e157-a943ffffac82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(to_indices([\"This is a sample sentence. What's up bro.\",\"This is a second sentence that will blow your mind.\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 1193, 534, 650, 1, 1, 1260, 96, 860, 302, 1, 1260, 3], [2, 1193, 534, 650, 697, 1, 1060, 120, 1, 1046, 1, 1260, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CU5ZPbUNYqv",
        "colab_type": "code",
        "outputId": "e2ddd223-d681-46df-97e9-3200d07c8c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "indices = to_indices(sentences)\n",
        "print(indices[:3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 707, 731, 1179, 789, 837, 665, 825, 204, 744, 9, 582, 417, 793, 1054, 3], [2, 825, 149, 607, 483, 521, 851, 235, 844, 22, 373, 650, 773, 1261, 797, 1, 400, 1, 3], [2, 1, 283, 20, 363, 937, 1193, 788, 1013, 1013, 1013, 1013, 1013, 96, 665, 438, 913, 619, 1132, 1089, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0pAiuF0ZUVF",
        "colab_type": "text"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5-oGlFgNuQE",
        "colab_type": "code",
        "outputId": "5c55a97c-21dc-4c3b-c1ac-a097ce40af0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_LEN = max(list(map(len,indices)))\n",
        "print(MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nd5w_hJO3UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padding function\n",
        "\n",
        "\n",
        "def pad_sentences(sentences, max_len):\n",
        "  \n",
        "  pad_index = word2idx[\"<pad>\"]\n",
        "  \n",
        "  for sen in sentences:\n",
        "    sen += (max_len-len(sen))*[pad_index]\n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvql6_W3P-Q0",
        "colab_type": "code",
        "outputId": "0167ef62-6f8d-49d6-fae8-1002788b13e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "temp_indices = indices\n",
        "\n",
        "pad_sentences(temp_indices,MAX_LEN)\n",
        "\n",
        "print(temp_indices[:4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 707, 731, 1179, 789, 837, 665, 825, 204, 744, 9, 582, 417, 793, 1054, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 825, 149, 607, 483, 521, 851, 235, 844, 22, 373, 650, 773, 1261, 797, 1, 400, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 1, 283, 20, 363, 937, 1193, 788, 1013, 1013, 1013, 1013, 1013, 96, 665, 438, 913, 619, 1132, 1089, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 188, 616, 1046, 119, 454, 761, 758, 942, 650, 61, 190, 1260, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3aW4CBsRTuW",
        "colab_type": "code",
        "outputId": "7163165c-1532-44dc-a371-27f96abbfd70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_input = np.array(temp_indices)\n",
        "\n",
        "print(model_input.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 37)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7fTalA9SNWI",
        "colab_type": "text"
      },
      "source": [
        "## Generating Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpcPzU6wRfXB",
        "colab_type": "code",
        "outputId": "3aa4695b-2a22-4537-c39e-d4be58442081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tokens = nlp(\"Go away. cdbcjdksnk\")\n",
        "for tok in tokens:\n",
        "  print(tok.text)\n",
        "  print(tok.is_oov)\n",
        "  print(tok.vector.shape)\n",
        "  print(tok.vector)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go\n",
            "False\n",
            "(300,)\n",
            "[ 1.3893e-01 -1.9056e-02 -3.3891e-01  1.2151e-01  3.6523e-01 -1.7391e-01\n",
            " -2.6735e-02 -5.0335e-02  2.4743e-01  2.4531e+00 -4.2113e-01  2.3632e-01\n",
            "  2.0513e-01 -1.0937e-02 -1.1480e-01 -3.7648e-02 -1.3440e-01  8.6124e-01\n",
            " -3.5803e-01  9.2525e-02  2.8075e-01  1.3649e-01  2.0819e-01  6.0206e-02\n",
            " -1.8229e-01  1.0172e-01 -1.3200e-01 -3.1598e-01  2.2241e-01 -1.9076e-01\n",
            " -1.0884e-02  1.6988e-01  8.0345e-03  1.3337e-01  1.7724e-01 -1.9162e-01\n",
            "  3.3681e-01  3.0186e-01  6.1654e-02  7.6906e-03 -5.4406e-01  5.0142e-02\n",
            " -4.3115e-02 -2.6241e-01  4.7462e-02  3.3670e-01 -2.8649e-01 -2.7414e-01\n",
            "  2.6776e-02 -6.5939e-02  1.1021e-01  2.8869e-01  4.6712e-01  1.2063e-01\n",
            "  3.3831e-01 -3.0427e-04 -1.2116e-01 -1.5900e-01 -1.0514e-01 -3.8560e-02\n",
            " -6.2205e-02  3.5631e-02 -1.7852e-01 -1.3308e-01  2.6103e-01 -1.1082e-01\n",
            " -2.7463e-01  1.8556e-01  4.5257e-01  3.0336e-01  6.1801e-02  7.7310e-02\n",
            "  3.4645e-01  3.6526e-03  4.6815e-01  2.0228e-02 -2.5509e-02 -1.9465e-02\n",
            " -5.3998e-03  8.6497e-02 -5.3099e-02 -8.6426e-02 -4.6913e-01  6.5788e-02\n",
            " -1.2720e-01 -2.4254e-01  2.4149e-01 -3.7684e-01  6.5707e-01  1.4106e-01\n",
            " -2.1080e-01  1.1095e-01  1.2741e-01 -2.8938e-01 -7.5295e-02  4.4109e-02\n",
            "  5.4280e-02 -2.9666e-01  1.6423e-02  4.4086e-02  7.2862e-02 -3.0149e-01\n",
            "  3.4613e-02  8.6731e-02  3.1091e-01 -3.7156e-01  1.7382e-01  2.1996e-01\n",
            "  6.0312e-02  1.6767e-01  3.8469e-02 -6.3231e-01  3.2331e-01  1.0421e-01\n",
            "  2.5080e-01  2.6267e-01  1.7882e-01 -2.4515e-01 -1.7214e-01  2.8319e-01\n",
            "  6.5598e-02 -4.4386e-02  3.7064e-02  4.5018e-02  3.9367e-01 -1.3580e-01\n",
            " -4.6021e-02  2.3260e-01  3.4156e-02  8.4838e-02  3.8056e-02 -3.4659e-03\n",
            " -6.8177e-02  8.2606e-02  1.5811e-01 -1.9388e-01  6.1247e-02 -3.4282e-01\n",
            " -2.3392e-01  9.1131e-02 -2.0934e+00  1.3815e-01  1.7597e-01 -3.8005e-01\n",
            "  2.4690e-01 -2.2482e-01 -5.9415e-02  4.2415e-01 -1.3768e-01 -6.4184e-02\n",
            " -6.3230e-02  1.0228e-01  3.9662e-02 -2.8910e-01  8.0242e-02 -4.2854e-01\n",
            "  1.0474e-01 -1.4070e-01 -5.0420e-02 -1.3486e-01 -1.3077e-01 -1.1560e-01\n",
            " -3.7648e-01  1.4467e-02  2.8400e-02 -1.4921e-01  2.9029e-01 -9.9163e-02\n",
            "  2.2967e-01  4.9717e-02 -2.4345e-01  2.7722e-02  7.4055e-02 -4.2579e-01\n",
            "  1.6724e-01  6.5469e-02  7.7571e-02  2.1529e-01 -7.1330e-02 -5.2742e-02\n",
            "  1.2080e-01 -5.6503e-02 -3.5852e-01 -8.5641e-02  5.3364e-01  1.8189e-01\n",
            " -1.7887e-01 -2.0100e-01  4.3655e-01  1.7912e-01  2.2238e-02 -4.8491e-02\n",
            " -8.8347e-02 -1.7544e-01 -1.7052e-01  2.7578e-01 -2.7629e-01 -5.6030e-02\n",
            "  3.0416e-01  4.5115e-01  6.8440e-02 -1.5926e-01 -2.7197e-01 -2.2628e-02\n",
            "  3.4567e-01 -8.8622e-02  1.9358e-01 -4.1653e-02  4.1661e-01  1.0848e-01\n",
            " -6.9752e-02 -2.3749e-01 -1.8511e-01  8.8535e-03 -1.2773e-01 -8.2802e-02\n",
            "  4.5794e-02  3.3554e-01 -3.0644e-01  4.4171e-01  1.5975e-01 -1.2756e-02\n",
            " -2.6972e-01 -7.8977e-02 -4.8264e-02 -6.5962e-02 -3.0006e-01  1.0440e-01\n",
            " -1.2715e-01 -1.4488e-02 -3.5107e-01 -1.1407e-01  6.6343e-01  1.6589e-01\n",
            "  1.5040e-02 -8.3249e-03  1.3835e-02 -1.9600e-01 -3.6130e-02  2.0337e-01\n",
            "  1.1822e-01  1.4760e-01 -3.9074e-02  2.4619e-01 -9.6280e-02 -2.2719e-01\n",
            " -2.2597e-01  1.9236e-01 -4.1362e-01  3.7821e-01  2.8114e-01 -7.8232e-02\n",
            " -2.4852e-01  8.4978e-02  4.5680e-01  4.7818e-01 -7.2192e-02 -2.2441e-01\n",
            " -2.5713e-01  1.1820e-01  1.8028e-01  5.1181e-01  4.0904e-01 -2.4304e-01\n",
            "  4.9090e-01 -3.9707e-01 -5.1963e-02  1.7818e-02  2.5160e-01  2.8290e-01\n",
            "  2.2776e-01 -2.5844e-01  1.4281e-01 -7.2607e-02  1.5194e-01  2.5309e-01\n",
            "  4.7232e-02  2.5905e-01 -9.3313e-02  1.1226e-01 -1.7449e-01 -3.4896e-01\n",
            " -2.0145e-01  1.1628e-01 -1.0769e-01 -7.8528e-02  9.3096e-02 -1.6539e-01\n",
            "  4.3994e-02  5.9698e-02 -1.3047e-01  7.2147e-02  3.3663e-03 -1.8181e-01\n",
            "  3.1465e-02 -3.5351e-02 -4.7912e-03  9.2753e-02  2.8618e-01  1.3646e-01]\n",
            "away\n",
            "False\n",
            "(300,)\n",
            "[ 3.5304e-01  1.0363e-01 -2.3219e-02  1.6994e-01  2.2273e-01 -2.6866e-01\n",
            " -4.6029e-01 -1.6171e-01 -2.6329e-02  2.9215e+00  4.2201e-02  3.8354e-01\n",
            " -9.1851e-02 -2.0215e-01 -1.5996e-01 -2.6707e-01 -2.3096e-02  7.1724e-01\n",
            " -1.5368e-01  1.9667e-01  9.3450e-02  2.2431e-01 -4.5946e-02  2.0516e-01\n",
            "  4.5254e-02 -6.4328e-02 -6.8254e-02 -2.3914e-01 -9.1989e-02 -3.1579e-02\n",
            " -4.4623e-02  2.6791e-01 -7.0116e-01 -1.1276e-01  2.3656e-01 -6.2714e-02\n",
            " -8.3753e-02  2.9793e-01  7.5563e-02  1.8955e-01  9.1433e-03 -1.2623e-01\n",
            " -2.2780e-01 -6.0437e-02  1.5138e-01  5.6420e-02 -3.1037e-01 -2.9385e-01\n",
            " -5.6120e-01  1.1390e-01  6.8345e-02  1.4628e-01 -1.4807e-01  5.7901e-02\n",
            "  3.9035e-02  9.5422e-02  2.7869e-02  1.0909e-01  7.5855e-02 -5.4035e-02\n",
            "  1.4988e-01 -4.9287e-02 -1.4671e-02 -1.2425e-01  1.5221e-01 -4.8012e-02\n",
            " -4.0782e-02  1.7211e-01  5.2506e-01  1.9979e-01  1.0595e-01  2.4865e-01\n",
            "  3.2821e-01  7.2999e-02 -1.4732e-01 -6.5991e-02  4.4869e-01 -7.2640e-02\n",
            "  2.5783e-01 -6.0328e-03  1.8762e-01  1.5110e-01 -1.0521e-01 -5.2421e-01\n",
            " -2.1856e-01 -8.2943e-02  2.0682e-01 -1.6651e-01  4.3160e-01  3.3651e-02\n",
            " -8.4639e-02  9.9755e-02 -1.7379e-02 -2.4150e-01  1.3040e-01  1.5354e-01\n",
            " -1.3611e-02 -1.4846e-01 -3.3388e-01 -1.5169e-01  3.7204e-01 -2.0926e-03\n",
            " -4.1497e-01  4.3478e-02  7.2363e-02 -6.3739e-01  4.1796e-01  4.4744e-01\n",
            " -2.6388e-02  4.5361e-02  2.3046e-01 -3.1138e-01  6.2302e-02  2.2638e-02\n",
            "  3.1745e-02 -6.0243e-02 -1.6962e-01  1.9643e-01 -9.0246e-02  3.2657e-01\n",
            "  1.5768e-01 -3.1938e-02  2.4542e-01 -1.8101e-01 -8.8511e-02 -5.9043e-02\n",
            " -1.6833e-01  2.1068e-01  1.3670e-01 -2.4973e-03 -2.1392e-01 -1.4560e-01\n",
            "  1.2442e-02 -1.3409e-01  1.1410e-01 -1.2108e-01 -1.1997e-01  3.2134e-01\n",
            "  5.5154e-02  1.1172e-01 -1.8040e+00  6.6584e-01  2.0435e-01 -2.0104e-01\n",
            "  2.9207e-01  1.9263e-01 -3.0436e-01  3.0665e-01  2.9047e-01  2.3514e-01\n",
            "  2.4794e-01 -1.5359e-01  2.1822e-01 -3.3597e-01 -2.3972e-01 -1.5798e-01\n",
            "  1.1817e-01  2.2918e-01 -2.7376e-02 -1.5565e-01 -9.9065e-03 -2.6714e-01\n",
            "  8.3654e-02  1.7275e-01  3.4605e-01  4.5365e-02 -8.7804e-02 -3.1855e-02\n",
            "  1.5528e-01  8.5429e-02  6.8158e-02 -2.9355e-01 -3.2460e-01 -4.9003e-01\n",
            " -1.6748e-01  1.7096e-02 -1.0664e-02 -1.1270e-01 -1.7818e-02 -1.4366e-02\n",
            "  1.4638e-01 -5.2395e-01  2.9739e-01 -2.1127e-01  3.8229e-01 -5.6099e-02\n",
            " -2.8048e-01 -1.2225e-01  4.8836e-01  2.4742e-01  2.3575e-01 -2.0536e-01\n",
            " -5.9764e-02 -8.9748e-02  1.0484e-02  4.6998e-02 -2.7580e-01 -3.2351e-01\n",
            " -1.8071e-01  3.7743e-01 -9.5900e-02 -1.8157e-01 -1.2827e-01  1.6270e-03\n",
            "  2.1273e-01  7.0190e-01  2.2544e-01 -3.7210e-01 -5.0002e-02 -5.5183e-01\n",
            "  2.8849e-02 -6.1673e-01  3.9224e-02 -1.5394e-02  2.1771e-01 -1.6891e-01\n",
            "  3.5813e-01  1.1967e-01 -2.2173e-01  1.5967e-01 -1.2560e-01 -1.1879e-01\n",
            " -2.8329e-01 -1.3860e-01 -4.1449e-01 -4.8557e-01 -7.8087e-02  2.9161e-01\n",
            " -2.1946e-01 -2.2612e-02  2.5133e-01  1.3254e-01  5.1145e-01 -9.3409e-03\n",
            "  8.9473e-02 -2.7226e-02  3.6963e-01 -3.5453e-02 -3.4281e-01  2.0391e-02\n",
            "  2.3915e-01  6.6627e-02 -1.1280e-01  4.8509e-01 -1.4833e-01 -1.9958e-01\n",
            " -4.6354e-01 -4.6540e-02 -3.0386e-01  3.5611e-01 -2.6931e-01 -2.6099e-01\n",
            "  1.6368e-01  7.3871e-02  1.5417e-01  6.3573e-01 -2.0032e-01 -3.7209e-01\n",
            "  2.9597e-02  2.8931e-01 -2.6501e-01  3.0159e-01  4.3859e-01 -1.8287e-01\n",
            "  6.0201e-01  7.0897e-02 -2.5262e-01 -2.9222e-01 -5.4163e-01 -2.9707e-01\n",
            "  5.6899e-02 -2.9808e-01 -4.0259e-02 -6.3577e-01  2.0426e-01  9.6710e-02\n",
            "  3.3035e-01  2.1733e-01 -4.5380e-01  9.4964e-05 -1.7173e-01 -8.6863e-02\n",
            " -1.1870e-01 -1.6054e-01 -7.8852e-02 -1.6888e-01  5.2253e-02 -3.0547e-01\n",
            "  2.1086e-03 -1.6985e-01 -2.3096e-01  6.9231e-02 -1.0990e-02  8.5580e-02\n",
            "  2.3520e-01  6.4638e-02 -3.3695e-03  3.1520e-01 -1.1035e-01 -5.2168e-02]\n",
            ".\n",
            "False\n",
            "(300,)\n",
            "[ 0.012001   0.20751   -0.12578   -0.59325    0.12525    0.15975\n",
            "  0.13748   -0.33157   -0.13694    1.7893    -0.47094    0.70434\n",
            "  0.26673   -0.089961  -0.18168    0.067226   0.053347   1.5595\n",
            " -0.2541     0.038413  -0.01409    0.056774   0.023434   0.024042\n",
            "  0.31703    0.19025   -0.37505    0.035603   0.1181     0.012032\n",
            " -0.037566  -0.5046    -0.049261   0.092351   0.11031   -0.073062\n",
            "  0.33994    0.28239    0.13413    0.070128  -0.022099  -0.28103\n",
            "  0.49607   -0.48693   -0.090964  -0.1538    -0.38011   -0.014228\n",
            " -0.19392   -0.11068   -0.014088  -0.17906    0.24509   -0.16878\n",
            " -0.15351   -0.13808    0.02151    0.13699    0.0068061 -0.14915\n",
            " -0.38169    0.12727    0.44007    0.32678   -0.46117    0.068687\n",
            "  0.34747    0.18827   -0.31837    0.4447    -0.2095    -0.26987\n",
            "  0.48945    0.15388    0.05295   -0.049831   0.11207    0.14881\n",
            " -0.37003    0.30777   -0.33865    0.045149  -0.18987    0.26634\n",
            " -0.26401   -0.47556    0.68381   -0.30653    0.24606    0.31611\n",
            " -0.071098   0.030417   0.088119   0.045025   0.20125   -0.21618\n",
            " -0.36371   -0.25948   -0.42398   -0.14305   -0.10208    0.21498\n",
            " -0.21924   -0.17935    0.21546    0.13801    0.24504   -0.2559\n",
            "  0.054815   0.21307    0.2564    -0.25673    0.17961   -0.47638\n",
            " -0.25181   -0.0091498 -0.054362  -0.21007    0.12597   -0.40795\n",
            " -0.021164   0.20585    0.18925   -0.0051896 -0.51394    0.28862\n",
            " -0.077748  -0.27676    0.46567   -0.14225   -0.17879   -0.4357\n",
            " -0.32481    0.15034   -0.058367   0.49652    0.20472    0.019866\n",
            "  0.13326    0.12823   -1.0177     0.29007    0.28995    0.029994\n",
            " -0.10763    0.28665   -0.24387    0.22905   -0.26249   -0.069269\n",
            " -0.17889    0.21936    0.15146    0.04567   -0.050497   0.071482\n",
            " -0.1027    -0.080705   0.30296    0.031302   0.26613   -0.0060951\n",
            "  0.10313   -0.39987   -0.043945  -0.057625   0.08702   -0.098152\n",
            "  0.22835   -0.005211   0.038075   0.01591   -0.20622    0.021853\n",
            "  0.0040426 -0.043063  -0.002294  -0.26097   -0.25802   -0.28158\n",
            " -0.23118   -0.010404  -0.30102   -0.4042     0.014653  -0.10445\n",
            "  0.30377   -0.20957    0.3119     0.068272   0.1008     0.010423\n",
            "  0.54011    0.29865    0.12653    0.013761   0.21738   -0.39521\n",
            "  0.066633   0.50327    0.14913   -0.11554    0.010042   0.095698\n",
            "  0.16607   -0.18808    0.055019   0.026715  -0.3164    -0.046583\n",
            " -0.051591   0.023475  -0.11007    0.085642   0.28394    0.040497\n",
            "  0.071986   0.14157   -0.021199   0.44718    0.20088   -0.12964\n",
            " -0.067183   0.47614    0.13394   -0.17287   -0.37324   -0.17285\n",
            "  0.02683   -0.1316     0.09116   -0.46487    0.1274    -0.090159\n",
            " -0.10552    0.068006  -0.13381    0.17056    0.089509  -0.23133\n",
            " -0.27572    0.061534  -0.051646   0.28377    0.25286   -0.24139\n",
            " -0.19905    0.12049   -0.1011     0.27392    0.27843    0.26449\n",
            " -0.18292   -0.048961   0.19198    0.17192    0.33659   -0.20184\n",
            " -0.34305   -0.24553   -0.15399    0.3945     0.22839   -0.25753\n",
            " -0.25675   -0.37332   -0.23884   -0.048816   0.78323    0.18851\n",
            " -0.26477    0.096566   0.062658  -0.30668   -0.43334    0.10006\n",
            "  0.21136    0.039459  -0.11077    0.24421    0.60942   -0.46646\n",
            "  0.086385  -0.39702   -0.23363    0.021307  -0.10778   -0.2281\n",
            "  0.50803    0.11567    0.16165   -0.066737  -0.29556    0.022612\n",
            " -0.28135    0.0635     0.14019    0.13871   -0.36049   -0.035    ]\n",
            "cdbcjdksnk\n",
            "True\n",
            "(300,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzkQNsrXS9pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}